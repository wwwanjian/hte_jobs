# This file was automatically generated by SWIG (http://www.swig.org).
# Version 3.0.8
#
# Do not make changes to this file unless you know what you are doing--modify
# the SWIG interface file instead.





from sys import version_info
if version_info >= (2, 6, 0):
    def swig_import_helper():
        from os.path import dirname
        import imp
        fp = None
        try:
            fp, pathname, description = imp.find_module('_regression', [dirname(__file__)])
        except ImportError:
            import _regression
            return _regression
        if fp is not None:
            try:
                _mod = imp.load_module('_regression', fp, pathname, description)
            finally:
                fp.close()
            return _mod
    _regression = swig_import_helper()
    del swig_import_helper
else:
    import _regression
del version_info
try:
    _swig_property = property
except NameError:
    pass  # Python < 2.2 doesn't have 'property'.


def _swig_setattr_nondynamic(self, class_type, name, value, static=1):
    if (name == "thisown"):
        return self.this.own(value)
    if (name == "this"):
        if type(value).__name__ == 'SwigPyObject':
            self.__dict__[name] = value
            return
    method = class_type.__swig_setmethods__.get(name, None)
    if method:
        return method(self, value)
    if (not static):
        object.__setattr__(self, name, value)
    else:
        raise AttributeError("You cannot add attributes to %s" % self)


def _swig_setattr(self, class_type, name, value):
    return _swig_setattr_nondynamic(self, class_type, name, value, 0)


def _swig_getattr_nondynamic(self, class_type, name, static=1):
    if (name == "thisown"):
        return self.this.own()
    method = class_type.__swig_getmethods__.get(name, None)
    if method:
        return method(self)
    if (not static):
        return object.__getattr__(self, name)
    else:
        raise AttributeError(name)

def _swig_getattr(self, class_type, name):
    return _swig_getattr_nondynamic(self, class_type, name, 0)


def _swig_repr(self):
    try:
        strthis = "proxy of " + self.this.__repr__()
    except Exception:
        strthis = ""
    return "<%s.%s; %s >" % (self.__class__.__module__, self.__class__.__name__, strthis,)

try:
    _object = object
    _newclass = 1
except AttributeError:
    class _object:
        pass
    _newclass = 0



def _swig_setattr_nondynamic_method(set):
    def set_attr(self, name, value):
        if (name == "thisown"):
            return self.this.own(value)
        if hasattr(self, name) or (name == "this"):
            set(self, name, value)
        else:
            raise AttributeError("You cannot add attributes to %s" % self)
    return set_attr


class default_random_engine(object):
    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr

    def __init__(self, *args):
        this = _regression.new_default_random_engine(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this

    def seed(self, arg2):
        return _regression.default_random_engine_seed(self, arg2)
    __swig_destroy__ = _regression.delete_default_random_engine
    __del__ = lambda self: None
default_random_engine_swigregister = _regression.default_random_engine_swigregister
default_random_engine_swigregister(default_random_engine)

class SwigPyIterator(object):
    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _regression.delete_SwigPyIterator
    __del__ = lambda self: None

    def value(self):
        return _regression.SwigPyIterator_value(self)

    def incr(self, n=1):
        return _regression.SwigPyIterator_incr(self, n)

    def decr(self, n=1):
        return _regression.SwigPyIterator_decr(self, n)

    def distance(self, x):
        return _regression.SwigPyIterator_distance(self, x)

    def equal(self, x):
        return _regression.SwigPyIterator_equal(self, x)

    def copy(self):
        return _regression.SwigPyIterator_copy(self)

    def next(self):
        return _regression.SwigPyIterator_next(self)

    def __next__(self):
        return _regression.SwigPyIterator___next__(self)

    def previous(self):
        return _regression.SwigPyIterator_previous(self)

    def advance(self, n):
        return _regression.SwigPyIterator_advance(self, n)

    def __eq__(self, x):
        return _regression.SwigPyIterator___eq__(self, x)

    def __ne__(self, x):
        return _regression.SwigPyIterator___ne__(self, x)

    def __iadd__(self, n):
        return _regression.SwigPyIterator___iadd__(self, n)

    def __isub__(self, n):
        return _regression.SwigPyIterator___isub__(self, n)

    def __add__(self, n):
        return _regression.SwigPyIterator___add__(self, n)

    def __sub__(self, *args):
        return _regression.SwigPyIterator___sub__(self, *args)
    def __iter__(self):
        return self
SwigPyIterator_swigregister = _regression.SwigPyIterator_swigregister
SwigPyIterator_swigregister(SwigPyIterator)

class num_vector(object):
    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr

    def iterator(self):
        return _regression.num_vector_iterator(self)
    def __iter__(self):
        return self.iterator()

    def __nonzero__(self):
        return _regression.num_vector___nonzero__(self)

    def __bool__(self):
        return _regression.num_vector___bool__(self)

    def __len__(self):
        return _regression.num_vector___len__(self)

    def __getslice__(self, i, j):
        return _regression.num_vector___getslice__(self, i, j)

    def __setslice__(self, *args):
        return _regression.num_vector___setslice__(self, *args)

    def __delslice__(self, i, j):
        return _regression.num_vector___delslice__(self, i, j)

    def __delitem__(self, *args):
        return _regression.num_vector___delitem__(self, *args)

    def __getitem__(self, *args):
        return _regression.num_vector___getitem__(self, *args)

    def __setitem__(self, *args):
        return _regression.num_vector___setitem__(self, *args)

    def pop(self):
        return _regression.num_vector_pop(self)

    def append(self, x):
        return _regression.num_vector_append(self, x)

    def empty(self):
        return _regression.num_vector_empty(self)

    def size(self):
        return _regression.num_vector_size(self)

    def swap(self, v):
        return _regression.num_vector_swap(self, v)

    def begin(self):
        return _regression.num_vector_begin(self)

    def end(self):
        return _regression.num_vector_end(self)

    def rbegin(self):
        return _regression.num_vector_rbegin(self)

    def rend(self):
        return _regression.num_vector_rend(self)

    def clear(self):
        return _regression.num_vector_clear(self)

    def get_allocator(self):
        return _regression.num_vector_get_allocator(self)

    def pop_back(self):
        return _regression.num_vector_pop_back(self)

    def erase(self, *args):
        return _regression.num_vector_erase(self, *args)

    def __init__(self, *args):
        this = _regression.new_num_vector(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this

    def push_back(self, x):
        return _regression.num_vector_push_back(self, x)

    def front(self):
        return _regression.num_vector_front(self)

    def back(self):
        return _regression.num_vector_back(self)

    def assign(self, n, x):
        return _regression.num_vector_assign(self, n, x)

    def resize(self, *args):
        return _regression.num_vector_resize(self, *args)

    def insert(self, *args):
        return _regression.num_vector_insert(self, *args)

    def reserve(self, n):
        return _regression.num_vector_reserve(self, n)

    def capacity(self):
        return _regression.num_vector_capacity(self)
    __swig_destroy__ = _regression.delete_num_vector
    __del__ = lambda self: None
num_vector_swigregister = _regression.num_vector_swigregister
num_vector_swigregister(num_vector)

class idx_vector(object):
    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr

    def iterator(self):
        return _regression.idx_vector_iterator(self)
    def __iter__(self):
        return self.iterator()

    def __nonzero__(self):
        return _regression.idx_vector___nonzero__(self)

    def __bool__(self):
        return _regression.idx_vector___bool__(self)

    def __len__(self):
        return _regression.idx_vector___len__(self)

    def __getslice__(self, i, j):
        return _regression.idx_vector___getslice__(self, i, j)

    def __setslice__(self, *args):
        return _regression.idx_vector___setslice__(self, *args)

    def __delslice__(self, i, j):
        return _regression.idx_vector___delslice__(self, i, j)

    def __delitem__(self, *args):
        return _regression.idx_vector___delitem__(self, *args)

    def __getitem__(self, *args):
        return _regression.idx_vector___getitem__(self, *args)

    def __setitem__(self, *args):
        return _regression.idx_vector___setitem__(self, *args)

    def pop(self):
        return _regression.idx_vector_pop(self)

    def append(self, x):
        return _regression.idx_vector_append(self, x)

    def empty(self):
        return _regression.idx_vector_empty(self)

    def size(self):
        return _regression.idx_vector_size(self)

    def swap(self, v):
        return _regression.idx_vector_swap(self, v)

    def begin(self):
        return _regression.idx_vector_begin(self)

    def end(self):
        return _regression.idx_vector_end(self)

    def rbegin(self):
        return _regression.idx_vector_rbegin(self)

    def rend(self):
        return _regression.idx_vector_rend(self)

    def clear(self):
        return _regression.idx_vector_clear(self)

    def get_allocator(self):
        return _regression.idx_vector_get_allocator(self)

    def pop_back(self):
        return _regression.idx_vector_pop_back(self)

    def erase(self, *args):
        return _regression.idx_vector_erase(self, *args)

    def __init__(self, *args):
        this = _regression.new_idx_vector(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this

    def push_back(self, x):
        return _regression.idx_vector_push_back(self, x)

    def front(self):
        return _regression.idx_vector_front(self)

    def back(self):
        return _regression.idx_vector_back(self)

    def assign(self, n, x):
        return _regression.idx_vector_assign(self, n, x)

    def resize(self, *args):
        return _regression.idx_vector_resize(self, *args)

    def insert(self, *args):
        return _regression.idx_vector_insert(self, *args)

    def reserve(self, n):
        return _regression.idx_vector_reserve(self, n)

    def capacity(self):
        return _regression.idx_vector_capacity(self)
    __swig_destroy__ = _regression.delete_idx_vector
    __del__ = lambda self: None
idx_vector_swigregister = _regression.idx_vector_swigregister
idx_vector_swigregister(idx_vector)

class num_vector_vector(object):
    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr

    def iterator(self):
        return _regression.num_vector_vector_iterator(self)
    def __iter__(self):
        return self.iterator()

    def __nonzero__(self):
        return _regression.num_vector_vector___nonzero__(self)

    def __bool__(self):
        return _regression.num_vector_vector___bool__(self)

    def __len__(self):
        return _regression.num_vector_vector___len__(self)

    def __getslice__(self, i, j):
        return _regression.num_vector_vector___getslice__(self, i, j)

    def __setslice__(self, *args):
        return _regression.num_vector_vector___setslice__(self, *args)

    def __delslice__(self, i, j):
        return _regression.num_vector_vector___delslice__(self, i, j)

    def __delitem__(self, *args):
        return _regression.num_vector_vector___delitem__(self, *args)

    def __getitem__(self, *args):
        return _regression.num_vector_vector___getitem__(self, *args)

    def __setitem__(self, *args):
        return _regression.num_vector_vector___setitem__(self, *args)

    def pop(self):
        return _regression.num_vector_vector_pop(self)

    def append(self, x):
        return _regression.num_vector_vector_append(self, x)

    def empty(self):
        return _regression.num_vector_vector_empty(self)

    def size(self):
        return _regression.num_vector_vector_size(self)

    def swap(self, v):
        return _regression.num_vector_vector_swap(self, v)

    def begin(self):
        return _regression.num_vector_vector_begin(self)

    def end(self):
        return _regression.num_vector_vector_end(self)

    def rbegin(self):
        return _regression.num_vector_vector_rbegin(self)

    def rend(self):
        return _regression.num_vector_vector_rend(self)

    def clear(self):
        return _regression.num_vector_vector_clear(self)

    def get_allocator(self):
        return _regression.num_vector_vector_get_allocator(self)

    def pop_back(self):
        return _regression.num_vector_vector_pop_back(self)

    def erase(self, *args):
        return _regression.num_vector_vector_erase(self, *args)

    def __init__(self, *args):
        this = _regression.new_num_vector_vector(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this

    def push_back(self, x):
        return _regression.num_vector_vector_push_back(self, x)

    def front(self):
        return _regression.num_vector_vector_front(self)

    def back(self):
        return _regression.num_vector_vector_back(self)

    def assign(self, n, x):
        return _regression.num_vector_vector_assign(self, n, x)

    def resize(self, *args):
        return _regression.num_vector_vector_resize(self, *args)

    def insert(self, *args):
        return _regression.num_vector_vector_insert(self, *args)

    def reserve(self, n):
        return _regression.num_vector_vector_reserve(self, n)

    def capacity(self):
        return _regression.num_vector_vector_capacity(self)
    __swig_destroy__ = _regression.delete_num_vector_vector
    __del__ = lambda self: None
num_vector_vector_swigregister = _regression.num_vector_vector_swigregister
num_vector_vector_swigregister(num_vector_vector)

class num_vector_vector_vector(object):
    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr

    def iterator(self):
        return _regression.num_vector_vector_vector_iterator(self)
    def __iter__(self):
        return self.iterator()

    def __nonzero__(self):
        return _regression.num_vector_vector_vector___nonzero__(self)

    def __bool__(self):
        return _regression.num_vector_vector_vector___bool__(self)

    def __len__(self):
        return _regression.num_vector_vector_vector___len__(self)

    def __getslice__(self, i, j):
        return _regression.num_vector_vector_vector___getslice__(self, i, j)

    def __setslice__(self, *args):
        return _regression.num_vector_vector_vector___setslice__(self, *args)

    def __delslice__(self, i, j):
        return _regression.num_vector_vector_vector___delslice__(self, i, j)

    def __delitem__(self, *args):
        return _regression.num_vector_vector_vector___delitem__(self, *args)

    def __getitem__(self, *args):
        return _regression.num_vector_vector_vector___getitem__(self, *args)

    def __setitem__(self, *args):
        return _regression.num_vector_vector_vector___setitem__(self, *args)

    def pop(self):
        return _regression.num_vector_vector_vector_pop(self)

    def append(self, x):
        return _regression.num_vector_vector_vector_append(self, x)

    def empty(self):
        return _regression.num_vector_vector_vector_empty(self)

    def size(self):
        return _regression.num_vector_vector_vector_size(self)

    def swap(self, v):
        return _regression.num_vector_vector_vector_swap(self, v)

    def begin(self):
        return _regression.num_vector_vector_vector_begin(self)

    def end(self):
        return _regression.num_vector_vector_vector_end(self)

    def rbegin(self):
        return _regression.num_vector_vector_vector_rbegin(self)

    def rend(self):
        return _regression.num_vector_vector_vector_rend(self)

    def clear(self):
        return _regression.num_vector_vector_vector_clear(self)

    def get_allocator(self):
        return _regression.num_vector_vector_vector_get_allocator(self)

    def pop_back(self):
        return _regression.num_vector_vector_vector_pop_back(self)

    def erase(self, *args):
        return _regression.num_vector_vector_vector_erase(self, *args)

    def __init__(self, *args):
        this = _regression.new_num_vector_vector_vector(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this

    def push_back(self, x):
        return _regression.num_vector_vector_vector_push_back(self, x)

    def front(self):
        return _regression.num_vector_vector_vector_front(self)

    def back(self):
        return _regression.num_vector_vector_vector_back(self)

    def assign(self, n, x):
        return _regression.num_vector_vector_vector_assign(self, n, x)

    def resize(self, *args):
        return _regression.num_vector_vector_vector_resize(self, *args)

    def insert(self, *args):
        return _regression.num_vector_vector_vector_insert(self, *args)

    def reserve(self, n):
        return _regression.num_vector_vector_vector_reserve(self, n)

    def capacity(self):
        return _regression.num_vector_vector_vector_capacity(self)
    __swig_destroy__ = _regression.delete_num_vector_vector_vector
    __del__ = lambda self: None
num_vector_vector_vector_swigregister = _regression.num_vector_vector_vector_swigregister
num_vector_vector_vector_swigregister(num_vector_vector_vector)

class num_num_pair(object):
    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr

    def __init__(self, *args):
        this = _regression.new_num_num_pair(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this
    first = _swig_property(_regression.num_num_pair_first_get, _regression.num_num_pair_first_set)
    second = _swig_property(_regression.num_num_pair_second_get, _regression.num_num_pair_second_set)
    def __len__(self):
        return 2
    def __repr__(self):
        return str((self.first, self.second))
    def __getitem__(self, index): 
        if not (index % 2):
            return self.first
        else:
            return self.second
    def __setitem__(self, index, val):
        if not (index % 2):
            self.first = val
        else:
            self.second = val
    __swig_destroy__ = _regression.delete_num_num_pair
    __del__ = lambda self: None
num_num_pair_swigregister = _regression.num_num_pair_swigregister
num_num_pair_swigregister(num_num_pair)

class data_base(object):
    """


    The interface for any data container with the minimal functionality.  

    C++ includes: data_container.hpp

    """

    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _regression.delete_data_base
    __del__ = lambda self: None

    def feature(self, feature_index, sample_index):
        """

        `feature(index_t feature_index, index_t sample_index) const =0 -> num_t`  

        Function for accessing a single feature value, consistency checks might be
        omitted for performance.  

        Parameters
        ----------
        * `feature_index` :  
            The index of the feature requested  
        * `sample_index` :  
            The index of the data point.  

        Returns
        -------
        the stored value  

        """
        return _regression.data_base_feature(self, feature_index, sample_index)


    def features(self, feature_index, sample_indices):
        """

        `features(index_t feature_index, const std::vector< index_t > &sample_indices)
            const =0 -> std::vector< num_t >`  

        member function for accessing the feature values of multiple data points at
        once, consistency checks might be omitted for performance  

        Parameters
        ----------
        * `feature_index` :  
            The index of the feature requested  
        * `sample_indices` :  
            The indices of the data point.  

        Returns
        -------
        the stored values  

        """
        return _regression.data_base_features(self, feature_index, sample_indices)


    def response(self, sample_index):
        """

        `response(index_t sample_index) const =0 -> response_t`  

        member function to query a single response value, consistency checks might be
        omitted for performance  

        Parameters
        ----------
        * `sample_index` :  
            the response of which data point  

        Returns
        -------
        the response value  

        """
        return _regression.data_base_response(self, sample_index)


    def weight(self, sample_index):
        """

        `weight(index_t sample_index) const =0 -> num_t`  

        function to access the weight attributed to a single data point  

        Parameters
        ----------
        * `sample_index` :  
            which data point  

        Returns
        -------
        the weigth of that sample  

        """
        return _regression.data_base_weight(self, sample_index)


    def add_data_point(self, features, response, weight):
        """

        `add_data_point(std::vector< num_t > features, response_t response, num_t
            weight)=0`  

        method to add a single data point  

        Parameters
        ----------
        * `features` :  
            a vector containing the features  
        * `response` :  
            the corresponding response value  
        * `weight` :  
            the weight of the data point  

        """
        return _regression.data_base_add_data_point(self, features, response, weight)


    def retrieve_data_point(self, index):
        """

        `retrieve_data_point(index_t index) const =0 -> std::vector< num_t >`  

        method to retrieve a data point  

        Parameters
        ----------
        * `index` :  
            index of the datapoint to extract  

        Returns
        -------
        std::vector<num_t> the features of the data point  

        """
        return _regression.data_base_retrieve_data_point(self, index)


    def get_type_of_feature(self, feature_index):
        """

        `get_type_of_feature(index_t feature_index) const =0 -> index_t`  

        query the type of a feature  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature  

        Returns
        -------
        int type of the feature: 0 - numerical value (float or int); n>0 - categorical
        value with n different values {0,1,...,n-1}  

        """
        return _regression.data_base_get_type_of_feature(self, feature_index)


    def get_type_of_response(self):
        """

        `get_type_of_response() const =0 -> index_t`  

        query the type of the response  

        Returns
        -------
        index_t type of the response: 0 - numerical value (float or int); n>0 -
        categorical value with n different values {0,1,...,n-1}  

        """
        return _regression.data_base_get_type_of_response(self)


    def set_type_of_feature(self, feature_index, feature_type):
        """

        `set_type_of_feature(index_t feature_index, index_t feature_type)=0`  

        specifying the type of a feature  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature whose type is specified  
        * `feature_type` :  
            the actual type (0 - numerical, value >0 catergorical with values from
            {0,1,...value-1}  

        """
        return _regression.data_base_set_type_of_feature(self, feature_index, feature_type)


    def set_type_of_response(self, response_type):
        """

        `set_type_of_response(index_t response_type)=0`  

        specifying the type of the response  

        Parameters
        ----------
        * `response_type` :  
            the actual type (0 - numerical, value >0 catergorical with values from
            {0,1,...value-1}  

        """
        return _regression.data_base_set_type_of_response(self, response_type)


    def set_bounds_of_feature(self, feature_index, min, max):
        """

        `set_bounds_of_feature(index_t feature_index, num_t min, num_t max)=0`  

        specifies the interval of allowed values for a feature  

        To marginalize out certain feature dimensions using non-i.i.d. data, the
        numerical bounds on each variable have to be known. This only applies to
        numerical features.  

        Note: The forest will not check if a datapoint is consistent with the specified
        bounds!  

        Parameters
        ----------
        * `feature_index` :  
            feature_index the index of the feature  
        * `min` :  
            the smallest value for the feature  
        * `max` :  
            the largest value for the feature  

        """
        return _regression.data_base_set_bounds_of_feature(self, feature_index, min, max)


    def get_bounds_of_feature(self, feature_index):
        """

        `get_bounds_of_feature(index_t feature_index) const =0 -> std::pair< num_t,
            num_t >`  

        query the allowed interval for a feature; applies only to continuous variables  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature  

        Returns
        -------
        std::pair<num_t,num_t> interval of allowed values  

        """
        return _regression.data_base_get_bounds_of_feature(self, feature_index)


    def num_features(self):
        """

        `num_features() const =0 -> index_t`  

        the number of features of every datapoint in the container  

        """
        return _regression.data_base_num_features(self)


    def num_data_points(self):
        """

        `num_data_points() const =0 -> index_t`  

        the number of data points in the container  

        """
        return _regression.data_base_num_data_points(self)

data_base_swigregister = _regression.data_base_swigregister
data_base_swigregister(data_base)

class default_data_container(data_base):
    """


    A data container for mostly continuous data.  

    It might happen that only a small fraction of all features is categorical. In
    that case it would be wasteful to store the type of every feature separately.
    Instead, this data_container only stores the non-continuous ones in a hash-map.  

    C++ includes: default_data_container.hpp

    """

    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr

    def __init__(self, num_f):
        """

        `default_container(index_t num_f)`  

        """
        this = _regression.new_default_data_container(num_f)
        try:
            self.this.append(this)
        except Exception:
            self.this = this

    def init_protected(self, num_f):
        """

        `init_protected(index_t num_f)`  

        """
        return _regression.default_data_container_init_protected(self, num_f)


    def feature(self, feature_index, sample_index):
        """

        `feature(index_t feature_index, index_t sample_index) const -> num_t`  

        Function for accessing a single feature value, consistency checks might be
        omitted for performance.  

        Parameters
        ----------
        * `feature_index` :  
            The index of the feature requested  
        * `sample_index` :  
            The index of the data point.  

        Returns
        -------
        the stored value  

        """
        return _regression.default_data_container_feature(self, feature_index, sample_index)


    def features(self, feature_index, sample_indices):
        """

        `features(index_t feature_index, const std::vector< index_t > &sample_indices)
            const -> std::vector< num_t >`  

        member function for accessing the feature values of multiple data points at
        once, consistency checks might be omitted for performance  

        Parameters
        ----------
        * `feature_index` :  
            The index of the feature requested  
        * `sample_indices` :  
            The indices of the data point.  

        Returns
        -------
        the stored values  

        """
        return _regression.default_data_container_features(self, feature_index, sample_indices)


    def response(self, sample_index):
        """

        `response(index_t sample_index) const -> response_t`  

        member function to query a single response value, consistency checks might be
        omitted for performance  

        Parameters
        ----------
        * `sample_index` :  
            the response of which data point  

        Returns
        -------
        the response value  

        """
        return _regression.default_data_container_response(self, sample_index)


    def add_data_point(self, features, response, weight=1):
        """

        `add_data_point(std::vector< num_t > features, response_t response, num_t
            weight=1)`  

        method to add a single data point  

        Parameters
        ----------
        * `features` :  
            a vector containing the features  
        * `response` :  
            the corresponding response value  
        * `weight` :  
            the weight of the data point  

        """
        return _regression.default_data_container_add_data_point(self, features, response, weight)


    def retrieve_data_point(self, index):
        """

        `retrieve_data_point(index_t index) const -> std::vector< num_t >`  

        method to retrieve a data point  

        Parameters
        ----------
        * `index` :  
            index of the datapoint to extract  

        Returns
        -------
        std::vector<num_t> the features of the data point  

        """
        return _regression.default_data_container_retrieve_data_point(self, index)


    def weight(self, sample_index):
        """

        `weight(index_t sample_index) const -> num_t`  

        function to access the weight attributed to a single data point  

        Parameters
        ----------
        * `sample_index` :  
            which data point  

        Returns
        -------
        the weigth of that sample  

        """
        return _regression.default_data_container_weight(self, sample_index)


    def get_type_of_feature(self, feature_index):
        """

        `get_type_of_feature(index_t feature_index) const -> index_t`  

        query the type of a feature  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature  

        Returns
        -------
        int type of the feature: 0 - numerical value (float or int); n>0 - categorical
        value with n different values {0,1,...,n-1}  

        As most features are assumed to be numerical, it is actually beneficial to store
        only the categorical exceptions in a hash-map. Type = 0 means continuous, and
        Type = n >= 1 means categorical with options in {0, n-1}.  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature  

        Returns
        -------
        int type of the feature: 0 - numerical value (float or int); n>0 - categorical
        value with n different values {1,2,...,n}  

        """
        return _regression.default_data_container_get_type_of_feature(self, feature_index)


    def set_type_of_feature(self, index, type):
        """

        `set_type_of_feature(index_t index, index_t type)`  

        specifying the type of a feature  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature whose type is specified  
        * `feature_type` :  
            the actual type (0 - numerical, value >0 catergorical with values from
            {0,1,...value-1}  

        """
        return _regression.default_data_container_set_type_of_feature(self, index, type)


    def num_features(self):
        """

        `num_features() const -> index_t`  

        the number of features of every datapoint in the container  

        """
        return _regression.default_data_container_num_features(self)


    def num_data_points(self):
        """

        `num_data_points() const -> index_t`  

        the number of data points in the container  

        """
        return _regression.default_data_container_num_data_points(self)


    def get_type_of_response(self):
        """

        `get_type_of_response() const -> index_t`  

        query the type of the response  

        Returns
        -------
        index_t type of the response: 0 - numerical value (float or int); n>0 -
        categorical value with n different values {0,1,...,n-1}  

        """
        return _regression.default_data_container_get_type_of_response(self)


    def set_type_of_response(self, resp_t):
        """

        `set_type_of_response(index_t resp_t)`  

        specifying the type of the response  

        Parameters
        ----------
        * `response_type` :  
            the actual type (0 - numerical, value >0 catergorical with values from
            {0,1,...value-1}  

        """
        return _regression.default_data_container_set_type_of_response(self, resp_t)


    def set_bounds_of_feature(self, feature_index, min, max):
        """

        `set_bounds_of_feature(index_t feature_index, num_t min, num_t max)`  

        specifies the interval of allowed values for a feature  

        To marginalize out certain feature dimensions using non-i.i.d. data, the
        numerical bounds on each variable have to be known. This only applies to
        numerical features.  

        Note: The forest will not check if a datapoint is consistent with the specified
        bounds!  

        Parameters
        ----------
        * `feature_index` :  
            feature_index the index of the feature  
        * `min` :  
            the smallest value for the feature  
        * `max` :  
            the largest value for the feature  

        """
        return _regression.default_data_container_set_bounds_of_feature(self, feature_index, min, max)


    def get_bounds_of_feature(self, feature_index):
        """

        `get_bounds_of_feature(index_t feature_index) const -> std::pair< num_t, num_t
            >`  

        query the allowed interval for a feature; applies only to continuous variables  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature  

        Returns
        -------
        std::pair<num_t,num_t> interval of allowed values  

        """
        return _regression.default_data_container_get_bounds_of_feature(self, feature_index)


    def get_min_max_of_feature(self, feature_index):
        """

        `get_min_max_of_feature(index_t feature_index) const -> std::pair< num_t, num_t
            >`  

        """
        return _regression.default_data_container_get_min_max_of_feature(self, feature_index)


    def guess_bounds_from_data(self):
        """

        `guess_bounds_from_data()`  

        """
        return _regression.default_data_container_guess_bounds_from_data(self)


    def normalize_data(self):
        """

        `normalize_data()`  

        """
        return _regression.default_data_container_normalize_data(self)


    def import_csv_files(self, *args):
        """

        `import_csv_files(const std::string &feature_file, const std::string
            &response_file, std::string weight_file="") -> int`  

        """
        return _regression.default_data_container_import_csv_files(self, *args)


    def check_consistency(self):
        """

        `check_consistency() -> bool`  

        """
        return _regression.default_data_container_check_consistency(self)


    def print_data(self):
        """

        `print_data()`  

        """
        return _regression.default_data_container_print_data(self)

    __swig_destroy__ = _regression.delete_default_data_container
    __del__ = lambda self: None
default_data_container_swigregister = _regression.default_data_container_swigregister
default_data_container_swigregister(default_data_container)

class default_data_container_with_instances(data_base):
    """


    A data container for mostly continuous data with instances.  

    Similar to the mostly_continuous_data container, but with the capability to
    handle instance features.  

    C++ includes: default_data_container_with_instances.hpp

    """

    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """

        `default_container_with_instances(index_t num_config_f, index_t num_instance_f)`  

        """
        this = _regression.new_default_data_container_with_instances(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this

    def feature(self, feature_index, sample_index):
        """

        `feature(index_t feature_index, index_t sample_index) const -> num_t`  

        Function for accessing a single feature value, consistency checks might be
        omitted for performance.  

        Parameters
        ----------
        * `feature_index` :  
            The index of the feature requested  
        * `sample_index` :  
            The index of the data point.  

        Returns
        -------
        the stored value  

        """
        return _regression.default_data_container_with_instances_feature(self, feature_index, sample_index)


    def features(self, feature_index, sample_indices):
        """

        `features(index_t feature_index, const std::vector< index_t > &sample_indices)
            const -> std::vector< num_t >`  

        member function for accessing the feature values of multiple data points at
        once, consistency checks might be omitted for performance  

        Parameters
        ----------
        * `feature_index` :  
            The index of the feature requested  
        * `sample_indices` :  
            The indices of the data point.  

        Returns
        -------
        the stored values  

        """
        return _regression.default_data_container_with_instances_features(self, feature_index, sample_indices)


    def response(self, sample_index):
        """

        `response(index_t sample_index) const -> response_t`  

        member function to query a single response value, consistency checks might be
        omitted for performance  

        Parameters
        ----------
        * `sample_index` :  
            the response of which data point  

        Returns
        -------
        the response value  

        """
        return _regression.default_data_container_with_instances_response(self, sample_index)


    def add_data_point(self, *args):
        """

        `add_data_point(index_t config_index, index_t instance_index, response_t r,
            num_t weight=1)`  

        """
        return _regression.default_data_container_with_instances_add_data_point(self, *args)


    def weight(self, sample_index):
        """

        `weight(index_t sample_index) const -> num_t`  

        function to access the weight attributed to a single data point  

        Parameters
        ----------
        * `sample_index` :  
            which data point  

        Returns
        -------
        the weigth of that sample  

        """
        return _regression.default_data_container_with_instances_weight(self, sample_index)


    def num_configurations(self):
        """

        `num_configurations() -> index_t`  

        """
        return _regression.default_data_container_with_instances_num_configurations(self)


    def num_instances(self):
        """

        `num_instances() -> index_t`  

        """
        return _regression.default_data_container_with_instances_num_instances(self)


    def add_configuration(self, config_features):
        """

        `add_configuration(const std::vector< num_t > &config_features) -> index_t`  

        """
        return _regression.default_data_container_with_instances_add_configuration(self, config_features)


    def add_instance(self, instance_features):
        """

        `add_instance(const std::vector< num_t > instance_features) -> index_t`  

        """
        return _regression.default_data_container_with_instances_add_instance(self, instance_features)


    def retrieve_data_point(self, index):
        """

        `retrieve_data_point(index_t index) const -> std::vector< num_t >`  

        method to retrieve a data point  

        Parameters
        ----------
        * `index` :  
            index of the datapoint to extract  

        Returns
        -------
        std::vector<num_t> the features of the data point  

        """
        return _regression.default_data_container_with_instances_retrieve_data_point(self, index)


    def get_type_of_feature(self, feature_index):
        """

        `get_type_of_feature(index_t feature_index) const -> index_t`  

        query the type of a feature  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature  

        Returns
        -------
        int type of the feature: 0 - numerical value (float or int); n>0 - categorical
        value with n different values {0,1,...,n-1}  

        """
        return _regression.default_data_container_with_instances_get_type_of_feature(self, feature_index)


    def set_type_of_configuration_feature(self, index, type):
        """

        `set_type_of_configuration_feature(index_t index, index_t type)`  

        """
        return _regression.default_data_container_with_instances_set_type_of_configuration_feature(self, index, type)


    def set_type_of_instance_feature(self, index, type):
        """

        `set_type_of_instance_feature(index_t index, index_t type)`  

        """
        return _regression.default_data_container_with_instances_set_type_of_instance_feature(self, index, type)


    def set_type_of_feature(self, index, type):
        """

        `set_type_of_feature(index_t index, index_t type)`  

        specifying the type of a feature  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature whose type is specified  
        * `feature_type` :  
            the actual type (0 - numerical, value >0 catergorical with values from
            {0,1,...value-1}  

        """
        return _regression.default_data_container_with_instances_set_type_of_feature(self, index, type)


    def num_features(self):
        """

        `num_features() const -> index_t`  

        the number of features of every datapoint in the container  

        """
        return _regression.default_data_container_with_instances_num_features(self)


    def num_data_points(self):
        """

        `num_data_points() const -> index_t`  

        the number of data points in the container  

        """
        return _regression.default_data_container_with_instances_num_data_points(self)


    def check_consistency(self):
        """

        `check_consistency()`  

        """
        return _regression.default_data_container_with_instances_check_consistency(self)


    def get_type_of_response(self):
        """

        `get_type_of_response() const -> index_t`  

        query the type of the response  

        Returns
        -------
        index_t type of the response: 0 - numerical value (float or int); n>0 -
        categorical value with n different values {0,1,...,n-1}  

        """
        return _regression.default_data_container_with_instances_get_type_of_response(self)


    def set_type_of_response(self, resp_t):
        """

        `set_type_of_response(index_t resp_t)`  

        specifying the type of the response  

        Parameters
        ----------
        * `response_type` :  
            the actual type (0 - numerical, value >0 catergorical with values from
            {0,1,...value-1}  

        """
        return _regression.default_data_container_with_instances_set_type_of_response(self, resp_t)


    def set_bounds_of_feature(self, feature_index, min, max):
        """

        `set_bounds_of_feature(index_t feature_index, num_t min, num_t max)`  

        specifies the interval of allowed values for a feature  

        To marginalize out certain feature dimensions using non-i.i.d. data, the
        numerical bounds on each variable have to be known. This only applies to
        numerical features.  

        Note: The forest will not check if a datapoint is consistent with the specified
        bounds!  

        Parameters
        ----------
        * `feature_index` :  
            feature_index the index of the feature  
        * `min` :  
            the smallest value for the feature  
        * `max` :  
            the largest value for the feature  

        """
        return _regression.default_data_container_with_instances_set_bounds_of_feature(self, feature_index, min, max)


    def get_bounds_of_feature(self, feature_index):
        """

        `get_bounds_of_feature(index_t feature_index) const -> std::pair< num_t, num_t
            >`  

        query the allowed interval for a feature; applies only to continuous variables  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature  

        Returns
        -------
        std::pair<num_t,num_t> interval of allowed values  

        """
        return _regression.default_data_container_with_instances_get_bounds_of_feature(self, feature_index)


    def get_instance_set(self):
        """

        `get_instance_set() -> std::vector< num_t >`  

        method to get instance as set_feature for
        predict_mean_var_of_mean_response_on_set method in regression forest  

        """
        return _regression.default_data_container_with_instances_get_instance_set(self)


    def get_configuration_set(self, configuration_index):
        """

        `get_configuration_set(num_t configuration_index) -> std::vector< num_t >`  

        """
        return _regression.default_data_container_with_instances_get_configuration_set(self, configuration_index)


    def get_features_by_configuration_and_instance(self, configuration_index, instance_index):
        """

        `get_features_by_configuration_and_instance(num_t configuration_index, num_t
            instance_index) -> std::vector< num_t >`  

        """
        return _regression.default_data_container_with_instances_get_features_by_configuration_and_instance(self, configuration_index, instance_index)

    __swig_destroy__ = _regression.delete_default_data_container_with_instances
    __del__ = lambda self: None
default_data_container_with_instances_swigregister = _regression.default_data_container_with_instances_swigregister
default_data_container_with_instances_swigregister(default_data_container_with_instances)

class tree_opts(object):
    """


    Attributes
    ----------
    * `max_features` : `index_t`  
        number of features to consider for each split  

    * `max_depth` : `index_t`  
        maximum depth for the tree  

    * `min_samples_to_split` : `index_t`  
        minumum number of samples to try splitting  

    * `min_weight_to_split` : `num_t`  
        minumum weight of samples to try splitting  

    * `min_samples_in_leaf` : `index_t`  
        minimum total sample weights in a leaf  

    * `min_weight_in_leaf` : `num_t`  
        minimum total sample weights in a leaf  

    * `max_num_nodes` : `index_t`  
        maxmimum total number of nodes in the tree  

    * `max_num_leaves` : `index_t`  
        maxmimum total number of leaves in the tree  

    * `epsilon_purity` : `response_t`  
        minimum difference between two response values to be considered different*/  

    * `life_time` : `num_t`  
        life time of a mondrian tree  

    * `hierarchical_smoothing` : `bool`  
        flag to enable/disable hierachical smoothing for mondrian forests  

    """

    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr
    max_features = _swig_property(_regression.tree_opts_max_features_get, _regression.tree_opts_max_features_set)
    max_depth = _swig_property(_regression.tree_opts_max_depth_get, _regression.tree_opts_max_depth_set)
    min_samples_to_split = _swig_property(_regression.tree_opts_min_samples_to_split_get, _regression.tree_opts_min_samples_to_split_set)
    min_weight_to_split = _swig_property(_regression.tree_opts_min_weight_to_split_get, _regression.tree_opts_min_weight_to_split_set)
    min_samples_in_leaf = _swig_property(_regression.tree_opts_min_samples_in_leaf_get, _regression.tree_opts_min_samples_in_leaf_set)
    min_weight_in_leaf = _swig_property(_regression.tree_opts_min_weight_in_leaf_get, _regression.tree_opts_min_weight_in_leaf_set)
    max_num_nodes = _swig_property(_regression.tree_opts_max_num_nodes_get, _regression.tree_opts_max_num_nodes_set)
    max_num_leaves = _swig_property(_regression.tree_opts_max_num_leaves_get, _regression.tree_opts_max_num_leaves_set)
    epsilon_purity = _swig_property(_regression.tree_opts_epsilon_purity_get, _regression.tree_opts_epsilon_purity_set)
    life_time = _swig_property(_regression.tree_opts_life_time_get, _regression.tree_opts_life_time_set)
    hierarchical_smoothing = _swig_property(_regression.tree_opts_hierarchical_smoothing_get, _regression.tree_opts_hierarchical_smoothing_set)

    def set_default_values(self):
        """

        `set_default_values()`  

        (Re)set to default values with no limits on the size of the tree  

        If nothing is know about the data, this member can be used to get a valid
        setting for the tree_options struct. But beware this setting could lead to a
        huge tree depending on the amount of data. There is no limit to the size, and
        nodes are split into pure leafs. For each split, every feature is considered!
        This not only slows the training down, but also makes this tree deterministic!  

        """
        return _regression.tree_opts_set_default_values(self)


    def __init__(self, *args):
        """

        `tree_options(rfr::data_containers::base< num_t, response_t, index_t > &data)`  

        Constructor that adjusts the number of features considered at each split
        proportional to the square root of the number of features.  

        """
        this = _regression.new_tree_opts(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this

    def adjust_limits_to_data(self, data):
        """

        `adjust_limits_to_data(const rfr::data_containers::base< num_t, response_t,
            index_t > &data)`  

        """
        return _regression.tree_opts_adjust_limits_to_data(self, data)


    def print_info(self):
        """

        `print_info()`  

        """
        return _regression.tree_opts_print_info(self)

    __swig_destroy__ = _regression.delete_tree_opts
    __del__ = lambda self: None
tree_opts_swigregister = _regression.tree_opts_swigregister
tree_opts_swigregister(tree_opts)

class base_tree(object):
    """


    """

    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _regression.delete_base_tree
    __del__ = lambda self: None

    def fit(self, *args):
        """

        `fit(const rfr::data_containers::base< num_t, response_t, index_t > &data,
            rfr::trees::tree_options< num_t, response_t, index_t > tree_opts, const
            std::vector< num_t > &sample_weights, rng_type &rng)=0`  

        fits a (possibly randomized) decision tree to a subset of the data  

        At each node, if it is 'splitworthy', a random subset of all features is
        considered for the split. Depending on the split_type provided, greedy or
        randomized choices can be made. Just make sure the max_features in tree_opts to
        a number smaller than the number of features!  

        Parameters
        ----------
        * `data` :  
            the container holding the training data  
        * `tree_opts` :  
            a tree_options opject that controls certain aspects of "growing" the tree  
        * `sample_weights` :  
            vector containing the weights of all datapoints, can be used for subsampling
            (no checks are done here!)  
        * `rng` :  
            a (pseudo) random number generator  

        """
        return _regression.base_tree_fit(self, *args)


    def predict(self, feature_vector):
        """

        `predict(const std::vector< num_t > &feature_vector) const =0 -> response_t`  

        predicts the response value for a single feature vector  

        Parameters
        ----------
        * `feature_vector` :  
            an array containing a valid (in terms of size and values!) feature vector  

        Returns
        -------
        num_t the prediction of the response value (usually the mean of all responses in
        the corresponding leaf)  

        """
        return _regression.base_tree_predict(self, feature_vector)


    def leaf_entries(self, feature_vector):
        """

        `leaf_entries(const std::vector< num_t > &feature_vector) const =0 ->
            std::vector< response_t > const  &`  

        returns all response values in the leaf into which the given feature vector
        falls  

        Parameters
        ----------
        * `feature_vector` :  
            an array containing a valid (in terms of size and values!) feature vector  

        Returns
        -------
        std::vector<response_t> all response values in that leaf  

        """
        return _regression.base_tree_leaf_entries(self, feature_vector)


    def number_of_nodes(self):
        """

        `number_of_nodes() const =0 -> index_t`  

        """
        return _regression.base_tree_number_of_nodes(self)


    def number_of_leafs(self):
        """

        `number_of_leafs() const =0 -> index_t`  

        """
        return _regression.base_tree_number_of_leafs(self)


    def depth(self):
        """

        `depth() const =0 -> index_t`  

        """
        return _regression.base_tree_depth(self)


    def save_latex_representation(self, filename):
        """

        `save_latex_representation(const char *filename) const =0`  

        creates a LaTeX document visualizing the tree  

        """
        return _regression.base_tree_save_latex_representation(self, filename)

base_tree_swigregister = _regression.base_tree_swigregister
base_tree_swigregister(base_tree)

class binary_full_tree_rss(base_tree):
    """


    """

    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr

    def __init__(self):
        """

        `k_ary_random_tree()`  

        """
        this = _regression.new_binary_full_tree_rss()
        try:
            self.this.append(this)
        except Exception:
            self.this = this
    __swig_destroy__ = _regression.delete_binary_full_tree_rss
    __del__ = lambda self: None

    def fit(self, data, tree_opts, sample_weights, rng):
        """

        `fit(const rfr::data_containers::base< num_t, response_t, index_t > &data,
            rfr::trees::tree_options< num_t, response_t, index_t > tree_opts, const
            std::vector< num_t > &sample_weights, rng_type &rng)`  

        fits a randomized decision tree to a subset of the data  

        At each node, if it is 'splitworthy', a random subset of all features is
        considered for the split. Depending on the split_type provided, greedy or
        randomized choices can be made. Just make sure the max_features in tree_opts to
        a number smaller than the number of features!  

        Parameters
        ----------
        * `data` :  
            the container holding the training data  
        * `tree_opts` :  
            a tree_options object that controls certain aspects of "growing" the tree  
        * `sample_weights` :  
            vector containing the weights of all allowed datapoints (set to individual
            entries to zero for subsampling), no checks are done here!  
        * `rng` :  
            the random number generator to be used  

        """
        return _regression.binary_full_tree_rss_fit(self, data, tree_opts, sample_weights, rng)


    def find_leaf_index(self, feature_vector):
        """

        `find_leaf_index(const std::vector< num_t > &feature_vector) const -> index_t`  

        """
        return _regression.binary_full_tree_rss_find_leaf_index(self, feature_vector)


    def get_leaf(self, feature_vector):
        """

        `get_leaf(const std::vector< num_t > &feature_vector) const -> const node_type
            &`  

        """
        return _regression.binary_full_tree_rss_get_leaf(self, feature_vector)


    def leaf_entries(self, feature_vector):
        """

        `leaf_entries(const std::vector< num_t > &feature_vector) const -> std::vector<
            response_t > const  &`  

        returns all response values in the leaf into which the given feature vector
        falls  

        Parameters
        ----------
        * `feature_vector` :  
            an array containing a valid (in terms of size and values!) feature vector  

        Returns
        -------
        std::vector<response_t> all response values in that leaf  

        """
        return _regression.binary_full_tree_rss_leaf_entries(self, feature_vector)


    def leaf_statistic(self, feature_vector):
        """

        `leaf_statistic(const std::vector< num_t > &feature_vector) const ->
            rfr::util::weighted_running_statistics< num_t > const  &`  

        """
        return _regression.binary_full_tree_rss_leaf_statistic(self, feature_vector)


    def predict(self, feature_vector):
        """

        `predict(const std::vector< num_t > &feature_vector) const -> response_t`  

        predicts the response value for a single feature vector  

        Parameters
        ----------
        * `feature_vector` :  
            an array containing a valid (in terms of size and values!) feature vector  

        Returns
        -------
        num_t the prediction of the response value (usually the mean of all responses in
        the corresponding leaf)  

        """
        return _regression.binary_full_tree_rss_predict(self, feature_vector)


    def marginalized_mean_prediction(self, feature_vector, node_index=0):
        """

        `marginalized_mean_prediction(const std::vector< num_t > &feature_vector,
            index_t node_index=0) const -> num_t`  

        """
        return _regression.binary_full_tree_rss_marginalized_mean_prediction(self, feature_vector, node_index)


    def number_of_nodes(self):
        """

        `number_of_nodes() const -> index_t`  

        """
        return _regression.binary_full_tree_rss_number_of_nodes(self)


    def number_of_leafs(self):
        """

        `number_of_leafs() const -> index_t`  

        """
        return _regression.binary_full_tree_rss_number_of_leafs(self)


    def depth(self):
        """

        `depth() const -> index_t`  

        """
        return _regression.binary_full_tree_rss_depth(self)


    def partition_recursor(self, the_partition, subspace, node_index):
        """

        `partition_recursor(std::vector< std::vector< std::vector< num_t > > >
            &the_partition, std::vector< std::vector< num_t > > &subspace, num_t
            node_index) const`  

        """
        return _regression.binary_full_tree_rss_partition_recursor(self, the_partition, subspace, node_index)


    def partition(self, pcs):
        """

        `partition(std::vector< std::vector< num_t > > pcs) const -> std::vector<
            std::vector< std::vector< num_t > > >`  

        """
        return _regression.binary_full_tree_rss_partition(self, pcs)


    def total_weight_in_subtree(self, node_index):
        """

        `total_weight_in_subtree(index_t node_index) const -> num_t`  

        """
        return _regression.binary_full_tree_rss_total_weight_in_subtree(self, node_index)


    def check_split_fractions(self, epsilon=1e-6):
        """

        `check_split_fractions(num_t epsilon=1e-6) const -> bool`  

        """
        return _regression.binary_full_tree_rss_check_split_fractions(self, epsilon)


    def pseudo_update(self, features, response, weight):
        """

        `pseudo_update(std::vector< num_t > features, response_t response, num_t
            weight)`  

        """
        return _regression.binary_full_tree_rss_pseudo_update(self, features, response, weight)


    def pseudo_downdate(self, features, response, weight):
        """

        `pseudo_downdate(std::vector< num_t > features, response_t response, num_t
            weight)`  

        """
        return _regression.binary_full_tree_rss_pseudo_downdate(self, features, response, weight)


    def print_info(self):
        """

        `print_info() const`  

        """
        return _regression.binary_full_tree_rss_print_info(self)


    def save_latex_representation(self, filename):
        """

        `save_latex_representation(const char *filename) const`  

        a visualization by generating a LaTeX document that can be compiled  

        Parameters
        ----------
        * `filename` :  
            Name of the file that will be used. Note that any existing file will be
            silently overwritten!  

        """
        return _regression.binary_full_tree_rss_save_latex_representation(self, filename)

binary_full_tree_rss_swigregister = _regression.binary_full_tree_rss_swigregister
binary_full_tree_rss_swigregister(binary_full_tree_rss)

class forest_opts(object):
    """


    Attributes
    ----------
    * `num_trees` : `index_t`  
        number of trees in the forest  

    * `num_data_points_per_tree` : `index_t`  
        number of datapoints used in each tree  

    * `do_bootstrapping` : `bool`  
        flag to toggle bootstrapping  

    * `compute_oob_error` : `bool`  
        flag to enable/disable computing the out-of-bag error  

    * `tree_opts` : `rfr::trees::tree_options< num_t, response_t, index_t >`  
        the options for each tree  

    """

    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr
    num_trees = _swig_property(_regression.forest_opts_num_trees_get, _regression.forest_opts_num_trees_set)
    num_data_points_per_tree = _swig_property(_regression.forest_opts_num_data_points_per_tree_get, _regression.forest_opts_num_data_points_per_tree_set)
    do_bootstrapping = _swig_property(_regression.forest_opts_do_bootstrapping_get, _regression.forest_opts_do_bootstrapping_set)
    compute_oob_error = _swig_property(_regression.forest_opts_compute_oob_error_get, _regression.forest_opts_compute_oob_error_set)
    tree_opts = _swig_property(_regression.forest_opts_tree_opts_get, _regression.forest_opts_tree_opts_set)

    def set_default_values(self):
        """

        `set_default_values()`  

        (Re)set to default values for the forest.  

        """
        return _regression.forest_opts_set_default_values(self)


    def adjust_limits_to_data(self, data):
        """

        `adjust_limits_to_data(const rfr::data_containers::base< num_t, response_t,
            index_t > &data)`  

        adjusts all relevant variables to the data  

        """
        return _regression.forest_opts_adjust_limits_to_data(self, data)


    def __init__(self, *args):
        """

        `forest_options(rfr::trees::tree_options< num_t, response_t, index_t > &to,
            rfr::data_containers::base< num_t, response_t, index_t > &data)`  

        Constructor that adjusts to the data.  

        """
        this = _regression.new_forest_opts(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this

    def to_string(self):
        """

        `to_string() const -> std::string`  

        """
        return _regression.forest_opts_to_string(self)

    __swig_destroy__ = _regression.delete_forest_opts
    __del__ = lambda self: None
forest_opts_swigregister = _regression.forest_opts_swigregister
forest_opts_swigregister(forest_opts)

class binary_rss_forest(object):
    """


    Attributes
    ----------
    * `options` : `forest_options< num_t, response_t, index_t >`  

    """

    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr
    options = _swig_property(_regression.binary_rss_forest_options_get, _regression.binary_rss_forest_options_set)

    def __init__(self, *args):
        """

        `regression_forest(forest_options< num_t, response_t, index_t > opts)`  

        """
        this = _regression.new_binary_rss_forest(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this
    __swig_destroy__ = _regression.delete_binary_rss_forest
    __del__ = lambda self: None

    def fit(self, data, rng):
        """

        `fit(const rfr::data_containers::base< num_t, response_t, index_t > &data,
            rng_type &rng)`  

        growing the random forest for a given data set  

        Parameters
        ----------
        * `data` :  
            a filled data container  
        * `rng` :  
            the random number generator to be used  

        """
        return _regression.binary_rss_forest_fit(self, data, rng)


    def predict(self, feature_vector):
        """

        `predict(const std::vector< num_t > &feature_vector) const -> response_t`  

        """
        return _regression.binary_rss_forest_predict(self, feature_vector)


    def predict_mean_var(self, feature_vector, weighted_data=False):
        """

        `predict_mean_var(const std::vector< num_t > &feature_vector, bool
            weighted_data=false) -> std::pair< num_t, num_t >`  

        """
        return _regression.binary_rss_forest_predict_mean_var(self, feature_vector, weighted_data)


    def covariance(self, f1, f2):
        """

        `covariance(const std::vector< num_t > &f1, const std::vector< num_t > &f2) ->
            num_t`  

        """
        return _regression.binary_rss_forest_covariance(self, f1, f2)


    def kernel(self, f1, f2):
        """

        `kernel(const std::vector< num_t > &f1, const std::vector< num_t > &f2) ->
            num_t`  

        """
        return _regression.binary_rss_forest_kernel(self, f1, f2)


    def all_leaf_values(self, feature_vector):
        """

        `all_leaf_values(const std::vector< num_t > &feature_vector) const ->
            std::vector< std::vector< num_t > >`  

        """
        return _regression.binary_rss_forest_all_leaf_values(self, feature_vector)


    def pseudo_update(self, features, response, weight):
        """

        `pseudo_update(std::vector< num_t > features, response_t response, num_t
            weight)`  

        """
        return _regression.binary_rss_forest_pseudo_update(self, features, response, weight)


    def pseudo_downdate(self, features, response, weight):
        """

        `pseudo_downdate(std::vector< num_t > features, response_t response, num_t
            weight)`  

        """
        return _regression.binary_rss_forest_pseudo_downdate(self, features, response, weight)


    def out_of_bag_error(self):
        """

        `out_of_bag_error() -> num_t`  

        """
        return _regression.binary_rss_forest_out_of_bag_error(self)


    def save_to_binary_file(self, filename):
        """

        `save_to_binary_file(const std::string filename)`  

        """
        return _regression.binary_rss_forest_save_to_binary_file(self, filename)


    def load_from_binary_file(self, filename):
        """

        `load_from_binary_file(const std::string filename)`  

        """
        return _regression.binary_rss_forest_load_from_binary_file(self, filename)


    def ascii_string_representation(self):
        """

        `ascii_string_representation() -> std::string`  

        """
        return _regression.binary_rss_forest_ascii_string_representation(self)


    def load_from_ascii_string(self, str):
        """

        `load_from_ascii_string(std::string const &str)`  

        """
        return _regression.binary_rss_forest_load_from_ascii_string(self, str)


    def save_latex_representation(self, filename_template):
        """

        `save_latex_representation(const std::string filename_template)`  

        """
        return _regression.binary_rss_forest_save_latex_representation(self, filename_template)


    def print_info(self):
        """

        `print_info()`  

        """
        return _regression.binary_rss_forest_print_info(self)


    def num_trees(self):
        """

        `num_trees() -> unsigned int`  

        """
        return _regression.binary_rss_forest_num_trees(self)


    def __getstate__(self):
    	d = {}
    	d['str_representation'] = self.ascii_string_representation()
    	return (d)

    def __setstate__(self, sState):
    	self.__init__()
    	self.load_from_ascii_string(sState['str_representation'])

binary_rss_forest_swigregister = _regression.binary_rss_forest_swigregister
binary_rss_forest_swigregister(binary_rss_forest)

class qr_forest(binary_rss_forest):
    """


    """

    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """

        `quantile_regression_forest(forest_options< num_t, response_t, index_t >
            forest_opts)`  

        """
        this = _regression.new_qr_forest(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this
    __swig_destroy__ = _regression.delete_qr_forest
    __del__ = lambda self: None

    def predict_quantiles(self, feature_vector, quantiles):
        """

        `predict_quantiles(const std::vector< num_t > &feature_vector, std::vector<
            num_t > quantiles) const -> std::vector< num_t >`  

        """
        return _regression.qr_forest_predict_quantiles(self, feature_vector, quantiles)

qr_forest_swigregister = _regression.qr_forest_swigregister
qr_forest_swigregister(qr_forest)

class fanova_forest_prototype(object):
    """


    Attributes
    ----------
    * `options` : `forest_options< num_t, response_t, index_t >`  

    """

    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr
    options = _swig_property(_regression.fanova_forest_prototype_options_get, _regression.fanova_forest_prototype_options_set)

    def __init__(self, *args):
        """

        `regression_forest(forest_options< num_t, response_t, index_t > opts)`  

        """
        this = _regression.new_fanova_forest_prototype(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this
    __swig_destroy__ = _regression.delete_fanova_forest_prototype
    __del__ = lambda self: None

    def fit(self, data, rng):
        """

        `fit(const rfr::data_containers::base< num_t, response_t, index_t > &data,
            rng_type &rng)`  

        growing the random forest for a given data set  

        Parameters
        ----------
        * `data` :  
            a filled data container  
        * `rng` :  
            the random number generator to be used  

        """
        return _regression.fanova_forest_prototype_fit(self, data, rng)


    def predict(self, feature_vector):
        """

        `predict(const std::vector< num_t > &feature_vector) const -> response_t`  

        """
        return _regression.fanova_forest_prototype_predict(self, feature_vector)


    def predict_mean_var(self, feature_vector, weighted_data=False):
        """

        `predict_mean_var(const std::vector< num_t > &feature_vector, bool
            weighted_data=false) -> std::pair< num_t, num_t >`  

        """
        return _regression.fanova_forest_prototype_predict_mean_var(self, feature_vector, weighted_data)


    def covariance(self, f1, f2):
        """

        `covariance(const std::vector< num_t > &f1, const std::vector< num_t > &f2) ->
            num_t`  

        """
        return _regression.fanova_forest_prototype_covariance(self, f1, f2)


    def kernel(self, f1, f2):
        """

        `kernel(const std::vector< num_t > &f1, const std::vector< num_t > &f2) ->
            num_t`  

        """
        return _regression.fanova_forest_prototype_kernel(self, f1, f2)


    def all_leaf_values(self, feature_vector):
        """

        `all_leaf_values(const std::vector< num_t > &feature_vector) const ->
            std::vector< std::vector< num_t > >`  

        """
        return _regression.fanova_forest_prototype_all_leaf_values(self, feature_vector)


    def pseudo_update(self, features, response, weight):
        """

        `pseudo_update(std::vector< num_t > features, response_t response, num_t
            weight)`  

        """
        return _regression.fanova_forest_prototype_pseudo_update(self, features, response, weight)


    def pseudo_downdate(self, features, response, weight):
        """

        `pseudo_downdate(std::vector< num_t > features, response_t response, num_t
            weight)`  

        """
        return _regression.fanova_forest_prototype_pseudo_downdate(self, features, response, weight)


    def out_of_bag_error(self):
        """

        `out_of_bag_error() -> num_t`  

        """
        return _regression.fanova_forest_prototype_out_of_bag_error(self)


    def save_to_binary_file(self, filename):
        """

        `save_to_binary_file(const std::string filename)`  

        """
        return _regression.fanova_forest_prototype_save_to_binary_file(self, filename)


    def load_from_binary_file(self, filename):
        """

        `load_from_binary_file(const std::string filename)`  

        """
        return _regression.fanova_forest_prototype_load_from_binary_file(self, filename)


    def ascii_string_representation(self):
        """

        `ascii_string_representation() -> std::string`  

        """
        return _regression.fanova_forest_prototype_ascii_string_representation(self)


    def load_from_ascii_string(self, str):
        """

        `load_from_ascii_string(std::string const &str)`  

        """
        return _regression.fanova_forest_prototype_load_from_ascii_string(self, str)


    def save_latex_representation(self, filename_template):
        """

        `save_latex_representation(const std::string filename_template)`  

        """
        return _regression.fanova_forest_prototype_save_latex_representation(self, filename_template)


    def print_info(self):
        """

        `print_info()`  

        """
        return _regression.fanova_forest_prototype_print_info(self)


    def num_trees(self):
        """

        `num_trees() -> unsigned int`  

        """
        return _regression.fanova_forest_prototype_num_trees(self)

fanova_forest_prototype_swigregister = _regression.fanova_forest_prototype_swigregister
fanova_forest_prototype_swigregister(fanova_forest_prototype)

class fanova_forest(fanova_forest_prototype):
    """


    """

    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """

        `fANOVA_forest(forest_options< num_t, response_t, index_t > forest_opts)`  

        """
        this = _regression.new_fanova_forest(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this
    __swig_destroy__ = _regression.delete_fanova_forest
    __del__ = lambda self: None

    def fit(self, data, rng):
        """

        `fit(const rfr::data_containers::base< num_t, response_t, index_t > &data, rng_t
            &rng)`  

        growing the random forest for a given data set  

        Parameters
        ----------
        * `data` :  
            a filled data container  
        * `rng` :  
            the random number generator to be used  

        """
        return _regression.fanova_forest_fit(self, data, rng)


    def set_cutoffs(self, lower, upper):
        """

        `set_cutoffs(num_t lower, num_t upper)`  

        """
        return _regression.fanova_forest_set_cutoffs(self, lower, upper)


    def get_cutoffs(self):
        """

        `get_cutoffs() -> std::pair< num_t, num_t >`  

        """
        return _regression.fanova_forest_get_cutoffs(self)


    def precompute_marginals(self):
        """

        `precompute_marginals()`  

        """
        return _regression.fanova_forest_precompute_marginals(self)


    def marginal_mean_prediction(self, feature_vector):
        """

        `marginal_mean_prediction(const std::vector< num_t > &feature_vector) -> num_t`  

        """
        return _regression.fanova_forest_marginal_mean_prediction(self, feature_vector)


    def marginal_mean_variance_prediction(self, feature_vector):
        """

        `marginal_mean_variance_prediction(const std::vector< num_t > &feature_vector)
            -> std::pair< num_t, num_t >`  

        """
        return _regression.fanova_forest_marginal_mean_variance_prediction(self, feature_vector)


    def marginal_prediction_stat_of_tree(self, tree_index, feature_vector):
        """

        `marginal_prediction_stat_of_tree(index_t tree_index, const std::vector< num_t >
            &feature_vector) -> rfr::util::weighted_running_statistics< num_t >`  

        """
        return _regression.fanova_forest_marginal_prediction_stat_of_tree(self, tree_index, feature_vector)


    def get_trees_total_variances(self):
        """

        `get_trees_total_variances() -> std::vector< num_t >`  

        """
        return _regression.fanova_forest_get_trees_total_variances(self)


    def all_split_values(self):
        """

        `all_split_values() -> std::vector< std::vector< std::vector< num_t > > >`  

        """
        return _regression.fanova_forest_all_split_values(self)

fanova_forest_swigregister = _regression.fanova_forest_swigregister
fanova_forest_swigregister(fanova_forest)

class binary_mondrian_forest(object):
    """


    Attributes
    ----------
    * `options` : `forest_options< num_t, response_t, index_t >`  

    * `internal_index` : `index_t`  

    * `name` : `std::string`  

    """

    thisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')
    __setattr__ = _swig_setattr_nondynamic_method(object.__setattr__)
    class __metaclass__(type):
        __setattr__ = _swig_setattr_nondynamic_method(type.__setattr__)
    __repr__ = _swig_repr

    def get_trees(self):
        """

        `get_trees() const -> std::vector< tree_t >`  

        """
        return _regression.binary_mondrian_forest_get_trees(self)

    options = _swig_property(_regression.binary_mondrian_forest_options_get, _regression.binary_mondrian_forest_options_set)
    internal_index = _swig_property(_regression.binary_mondrian_forest_internal_index_get, _regression.binary_mondrian_forest_internal_index_set)
    name = _swig_property(_regression.binary_mondrian_forest_name_get, _regression.binary_mondrian_forest_name_set)

    def __init__(self, *args):
        """

        `mondrian_forest(forest_options< num_t, response_t, index_t > opts)`  

        """
        this = _regression.new_binary_mondrian_forest(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this
    __swig_destroy__ = _regression.delete_binary_mondrian_forest
    __del__ = lambda self: None

    def fit(self, data, rng):
        """

        `fit(const rfr::data_containers::base< num_t, response_t, index_t > &data, rng_t
            &rng)`  

        growing the random forest for a given data set  

        Parameters
        ----------
        * `data` :  
            a filled data container  
        * `rng` :  
            the random number generator to be used  

        """
        return _regression.binary_mondrian_forest_fit(self, data, rng)


    def predict_mean_var(self, feature_vector):
        """

        `predict_mean_var(const std::vector< num_t > &feature_vector) -> std::pair<
            num_t, num_t >`  

        """
        return _regression.binary_mondrian_forest_predict_mean_var(self, feature_vector)


    def predict(self, feature_vector):
        """

        `predict(const std::vector< num_t > &feature_vector) const -> response_t`  

        """
        return _regression.binary_mondrian_forest_predict(self, feature_vector)


    def predict_median(self, feature_vector):
        """

        `predict_median(const std::vector< num_t > &feature_vector) -> response_t`  

        """
        return _regression.binary_mondrian_forest_predict_median(self, feature_vector)


    def partial_fit(self, data, rng, point):
        """

        `partial_fit(const rfr::data_containers::base< num_t, response_t, index_t >
            &data, rng_t &rng, index_t point)`  

        """
        return _regression.binary_mondrian_forest_partial_fit(self, data, rng, point)


    def out_of_bag_error(self):
        """

        `out_of_bag_error() -> num_t`  

        """
        return _regression.binary_mondrian_forest_out_of_bag_error(self)


    def save_to_binary_file(self, filename):
        """

        `save_to_binary_file(const std::string filename)`  

        """
        return _regression.binary_mondrian_forest_save_to_binary_file(self, filename)


    def load_from_binary_file(self, filename):
        """

        `load_from_binary_file(const std::string filename)`  

        """
        return _regression.binary_mondrian_forest_load_from_binary_file(self, filename)


    def ascii_string_representation(self):
        """

        `ascii_string_representation() -> std::string`  

        """
        return _regression.binary_mondrian_forest_ascii_string_representation(self)


    def load_from_ascii_string(self, str):
        """

        `load_from_ascii_string(std::string const &str)`  

        """
        return _regression.binary_mondrian_forest_load_from_ascii_string(self, str)


    def save_latex_representation(self, filename_template):
        """

        `save_latex_representation(const std::string filename_template)`  

        """
        return _regression.binary_mondrian_forest_save_latex_representation(self, filename_template)


    def print_info(self):
        """

        `print_info()`  

        """
        return _regression.binary_mondrian_forest_print_info(self)


    def num_trees(self):
        """

        `num_trees() -> unsigned int`  

        """
        return _regression.binary_mondrian_forest_num_trees(self)

binary_mondrian_forest_swigregister = _regression.binary_mondrian_forest_swigregister
binary_mondrian_forest_swigregister(binary_mondrian_forest)



